import os
import gradio as gr

# --- 1. IMPORTACIONES MODERNAS (LangChain v0.2 + Integraciones Oficiales) ---
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma

# CAMBIO CR√çTICO 1: Usamos la librer√≠a dedicada para eliminar el Warning
# Si esto falla, aseg√∫rate de haber ejecutado: pip install langchain-huggingface
try:
    from langchain_huggingface import HuggingFaceEmbeddings
except ImportError:
    # Fallback por si no se instal√≥ la nueva librer√≠a
    from langchain_community.embeddings import HuggingFaceEmbeddings

# Configuraci√≥n e inicializaci√≥n
def inicializar_base_conocimiento():
    print("Inicializando base de conocimientos...")
    
    texto_base = """
Los clientes tienen 30 d√≠as calendario para solicitar devoluci√≥n.
El producto debe estar en condiciones comerciales.
Garant√≠a por defectos de fabricaci√≥n durante 12 meses.
El cliente debe presentar evidencia de compra.
El uso de la plataforma implica la aceptaci√≥n de t√©rminos.
Las responsabilidades y limitaciones est√°n descritas."""

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)
    docs = [Document(page_content=x) for x in text_splitter.split_text(texto_base)]

    # Modelo est√°ndar
    embedding_function = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )

    db = Chroma.from_documents(documents=docs, embedding=embedding_function)
    
    print("Base de conocimientos lista.")
    return db

# Inicializaci√≥n Global
vector_db = inicializar_base_conocimiento()

# RAG
def consultar_sistema_rag(pregunta):
    if not pregunta:
        return "Por favor, escribe una pregunta."

    docs_recuperados = vector_db.similarity_search(pregunta, k=2)
    
    contexto_texto = "\n\n".join([f"- {doc.page_content}" for doc in docs_recuperados])
    
    respuesta_final = (
        f"ü§ñ **Contexto recuperado:**\n\n"
        f"{contexto_texto}\n\n"
        f"--- \n"
        f"‚ÑπÔ∏è *Nota t√©cnica: Fragmentos recuperados por similitud vectorial.*"
    )
    return respuesta_final

# INTERFAZ GR√ÅFICA
tema_visual = gr.themes.Soft()

interfaz = gr.Interface(
    fn=consultar_sistema_rag,
    inputs=gr.Textbox(lines=2, placeholder="Ej: ¬øQu√© implica el uso de la plataforma?", label="Tu Pregunta"),
    outputs=gr.Markdown(label="Respuesta del Sistema"),
    title="üî¨ Demo RAG: Proyecto Omega",
    description="Interfaz de prueba para recuperaci√≥n de informaci√≥n sem√°ntica.",
    theme=tema_visual,  # Pasamos el objeto tema aqu√≠
    examples=[
        ["¬øCu√°l es la duraci√≥n de la garant√≠a?"],
        ["¬øCu√°l es el tiempo para solicitar una devoluci√≥n?"]
    ]
)

if __name__ == "__main__":
    interfaz.launch()